{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Mobilenet+Res10.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNwSDxQ3ULH/5l83/YUurXf",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Soedirman-Machine-Learning/Emotion-detection/blob/main/Mobilenet%2BRes10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZ7ouxj5kNAT"
      },
      "source": [
        "# Menghubungkan ke Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "839gXSZMzXb_",
        "outputId": "de2fba69-708f-4a50-adba-d498a798fb7b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEEWxlNKjXPn"
      },
      "source": [
        "#Menyimpan hasil ekstrak ke dalam folder datasets\n",
        "import zipfile,os\n",
        "local_zip = \"/content/drive/MyDrive/Colab Notebooks/Dataset_Emosi.zip\"\n",
        "zip_ref = zipfile.ZipFile(local_zip, \"r\")\n",
        "zip_ref.extractall(\"/content/datasets\")\n",
        "zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_6WxnbgkSyt"
      },
      "source": [
        "# Mengimpor Libraries yang digunakan"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npfKf3hEkAPI",
        "outputId": "9778b8ca-59e4-43d3-d373-32a156a10f66"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNet\n",
        "from tensorflow.keras.layers import AveragePooling2D\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from imutils import paths\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import argparse\n",
        "import os\n",
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "import cv2\n",
        "from keras.models import Sequential\n",
        "\n",
        " \n",
        "# Mengihitung waktu lamanya eksekusi tiap sel di Google Colab\n",
        "!pip install ipython-autotime\n",
        " \n",
        "%load_ext autotime"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ipython-autotime\n",
            "  Downloading https://files.pythonhosted.org/packages/b4/c9/b413a24f759641bc27ef98c144b590023c8038dfb8a3f09e713e9dff12c1/ipython_autotime-0.3.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from ipython-autotime) (5.5.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (4.3.3)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (51.3.3)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (2.6.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (1.0.18)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (4.4.2)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (4.8.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (0.8.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->ipython-autotime) (0.2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->ipython-autotime) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ipython-autotime) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->ipython-autotime) (0.7.0)\n",
            "Installing collected packages: ipython-autotime\n",
            "Successfully installed ipython-autotime-0.3.1\n",
            "time: 665 Âµs (started: 2021-01-24 16:57:24 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mlm415iAkgrI"
      },
      "source": [
        "# Menampilkan Versi TensorFlow yang digunakan"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "073FUBGC6coW",
        "outputId": "b0ec3971-5024-4e10-f68c-147ec9af7682"
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.0\n",
            "time: 2.18 ms (started: 2021-01-24 16:57:24 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-h79-4ykmMS"
      },
      "source": [
        "# Preprocessing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flWAOIE1NJsx",
        "outputId": "a9d33d2f-4d6d-48c6-9337-b1c4b97a303d"
      },
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255, \n",
        "    validation_split = 0.2,\n",
        "    rotation_range = 20,\n",
        "    horizontal_flip = True,\n",
        "    shear_range = 0.2,\n",
        "    zoom_range = 0.2,    \n",
        "    vertical_flip = True,\n",
        "    fill_mode = \"nearest\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 3.84 ms (started: 2021-01-24 16:57:25 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocKWllVxkrc3"
      },
      "source": [
        "# Membuat Objek ImageDataGenerator dan Data Augmentation\r\n",
        "\r\n",
        "Membuat obyek gambar dataset dengan imagedatagenerator, augmentasi dataset dan membagi dataset validasi sebesar 20% dan dataset pelatihan sebesar 80%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JH1iiugN6pKH",
        "outputId": "2db1390f-aab8-44b0-8ad7-fcef8effe0f7"
      },
      "source": [
        "#Memuat dataset pelatihan & validasi\n",
        "base_dir = os.path.join(\"/content/datasets/Dataset_Emosi/Train\")\n",
        " \n",
        "img_size =224\n",
        "batch_size = 128\n",
        " \n",
        "train_generator = datagen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=(img_size, img_size),\n",
        "    batch_size=batch_size, \n",
        "    subset='training')\n",
        " \n",
        "val_generator = datagen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=(img_size, img_size),\n",
        "    batch_size=batch_size, \n",
        "    subset='validation')\n",
        "\n",
        " \n",
        "#Memuat dataset pengujian\n",
        "X_test = []\n",
        "y_test = []\n",
        "labels = ['Marah',\n",
        "          'Sedih',\n",
        "          'Senang']\n",
        " \n",
        "for i,label in enumerate(labels):\n",
        "    folder = os.path.join(\"/content/datasets/Dataset_Emosi/Test\",label)\n",
        "    files = sorted(os.listdir(folder))\n",
        "    files = [x for x in files if x.endswith(\".jpg\")]\n",
        "    for k,file in enumerate(files):\n",
        "        image_path = os.path.join(folder, file)       \n",
        "        image = imread(image_path)/255.\n",
        "        image = resize(image,(224,224))\n",
        "        X_test.append(image)\n",
        "        category = os.path.split(folder)[-1]\n",
        "        y_test.append(i)\n",
        " \n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "\n",
        " \n",
        "#Menampilkan bentuk dari masing-masing dataset\n",
        "for image_batch, label_batch in train_generator:\n",
        "  break\n",
        "print(\"Bentuk array dari dataset train (pelatihan) adalah:\", image_batch.shape,label_batch.shape)\n",
        "for image_batch, label_batch in val_generator:\n",
        "  break\n",
        "print(\"Bentuk array dari dataset validation (validasi) adalah:\", image_batch.shape,label_batch.shape)\n",
        "print(\"Bentuk array dari dataset test (pengujian) adalah:\", X_test.shape,y_test.shape,)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 654 images belonging to 3 classes.\n",
            "Found 162 images belonging to 3 classes.\n",
            "Bentuk array dari dataset train (pelatihan) adalah: (128, 224, 224, 3) (128, 3)\n",
            "Bentuk array dari dataset validation (validasi) adalah: (128, 224, 224, 3) (128, 3)\n",
            "Bentuk array dari dataset test (pengujian) adalah: (204, 224, 224, 3) (204,)\n",
            "time: 7.32 s (started: 2021-01-24 16:57:25 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bWwsZnVlAMe"
      },
      "source": [
        "# Menyimpan Label Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5-H9xSYdP_U",
        "outputId": "c1559d61-f51c-4a78-fe89-9c42739d63d4"
      },
      "source": [
        "print (train_generator.class_indices)\n",
        "\n",
        "labels_txt = '\\n'.join(sorted(train_generator.class_indices.keys()))\n",
        "\n",
        "with open('labels.txt', 'w') as f:\n",
        "  f.write(labels_txt)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Marah': 0, 'Sedih': 1, 'Senang': 2}\n",
            "time: 5.21 ms (started: 2021-01-24 16:57:32 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2M6Uew6lEbf"
      },
      "source": [
        "# Membuat model dari jaringan CNN yang sudah dipelajari sebelumnya (pre-trained covnets)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0M4E6csX7tgJ",
        "outputId": "b8079996-06a9-42fd-9543-aee683524706"
      },
      "source": [
        "IMG_SHAPE = (224,224, 3)\n",
        "# Membuat model dasar (base model) dari pre-trained model \n",
        "base_model = tf.keras.applications.MobileNet(input_shape=IMG_SHAPE,\n",
        "                                             include_top=False,\n",
        "                                             weights='imagenet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf_no_top.h5\n",
            "17227776/17225924 [==============================] - 1s 0us/step\n",
            "time: 7.42 s (started: 2021-01-24 16:57:32 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86NjMd3ElPdU"
      },
      "source": [
        "# Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v96Ie4WYgRF3",
        "outputId": "bfc34dd5-e051-4bbd-8c84-6b813a0c3564"
      },
      "source": [
        "base_model.trainable = False\n",
        "base_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"mobilenet_1.00_224\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "conv1 (Conv2D)               (None, 112, 112, 32)      864       \n",
            "_________________________________________________________________\n",
            "conv1_bn (BatchNormalization (None, 112, 112, 32)      128       \n",
            "_________________________________________________________________\n",
            "conv1_relu (ReLU)            (None, 112, 112, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv_dw_1 (DepthwiseConv2D)  (None, 112, 112, 32)      288       \n",
            "_________________________________________________________________\n",
            "conv_dw_1_bn (BatchNormaliza (None, 112, 112, 32)      128       \n",
            "_________________________________________________________________\n",
            "conv_dw_1_relu (ReLU)        (None, 112, 112, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv_pw_1 (Conv2D)           (None, 112, 112, 64)      2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_1_bn (BatchNormaliza (None, 112, 112, 64)      256       \n",
            "_________________________________________________________________\n",
            "conv_pw_1_relu (ReLU)        (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv_pad_2 (ZeroPadding2D)   (None, 113, 113, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv_dw_2 (DepthwiseConv2D)  (None, 56, 56, 64)        576       \n",
            "_________________________________________________________________\n",
            "conv_dw_2_bn (BatchNormaliza (None, 56, 56, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv_dw_2_relu (ReLU)        (None, 56, 56, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv_pw_2 (Conv2D)           (None, 56, 56, 128)       8192      \n",
            "_________________________________________________________________\n",
            "conv_pw_2_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv_pw_2_relu (ReLU)        (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_3 (DepthwiseConv2D)  (None, 56, 56, 128)       1152      \n",
            "_________________________________________________________________\n",
            "conv_dw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv_dw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_3 (Conv2D)           (None, 56, 56, 128)       16384     \n",
            "_________________________________________________________________\n",
            "conv_pw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv_pw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv_pad_4 (ZeroPadding2D)   (None, 57, 57, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_4 (DepthwiseConv2D)  (None, 28, 28, 128)       1152      \n",
            "_________________________________________________________________\n",
            "conv_dw_4_bn (BatchNormaliza (None, 28, 28, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv_dw_4_relu (ReLU)        (None, 28, 28, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_4 (Conv2D)           (None, 28, 28, 256)       32768     \n",
            "_________________________________________________________________\n",
            "conv_pw_4_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv_pw_4_relu (ReLU)        (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_5 (DepthwiseConv2D)  (None, 28, 28, 256)       2304      \n",
            "_________________________________________________________________\n",
            "conv_dw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv_dw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_5 (Conv2D)           (None, 28, 28, 256)       65536     \n",
            "_________________________________________________________________\n",
            "conv_pw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv_pw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv_pad_6 (ZeroPadding2D)   (None, 29, 29, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_6 (DepthwiseConv2D)  (None, 14, 14, 256)       2304      \n",
            "_________________________________________________________________\n",
            "conv_dw_6_bn (BatchNormaliza (None, 14, 14, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv_dw_6_relu (ReLU)        (None, 14, 14, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_6 (Conv2D)           (None, 14, 14, 512)       131072    \n",
            "_________________________________________________________________\n",
            "conv_pw_6_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_6_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_7 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_7 (Conv2D)           (None, 14, 14, 512)       262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_8 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_8 (Conv2D)           (None, 14, 14, 512)       262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_9 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_9 (Conv2D)           (None, 14, 14, 512)       262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_10 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_10 (Conv2D)          (None, 14, 14, 512)       262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_11 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_11 (Conv2D)          (None, 14, 14, 512)       262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_pad_12 (ZeroPadding2D)  (None, 15, 15, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_12 (DepthwiseConv2D) (None, 7, 7, 512)         4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_12_bn (BatchNormaliz (None, 7, 7, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_12_relu (ReLU)       (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv_pw_12 (Conv2D)          (None, 7, 7, 1024)        524288    \n",
            "_________________________________________________________________\n",
            "conv_pw_12_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
            "_________________________________________________________________\n",
            "conv_pw_12_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
            "_________________________________________________________________\n",
            "conv_dw_13 (DepthwiseConv2D) (None, 7, 7, 1024)        9216      \n",
            "_________________________________________________________________\n",
            "conv_dw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
            "_________________________________________________________________\n",
            "conv_dw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
            "_________________________________________________________________\n",
            "conv_pw_13 (Conv2D)          (None, 7, 7, 1024)        1048576   \n",
            "_________________________________________________________________\n",
            "conv_pw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
            "_________________________________________________________________\n",
            "conv_pw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
            "=================================================================\n",
            "Total params: 3,228,864\n",
            "Trainable params: 0\n",
            "Non-trainable params: 3,228,864\n",
            "_________________________________________________________________\n",
            "time: 38.5 ms (started: 2021-01-24 16:57:39 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwCHwqhVlUoL"
      },
      "source": [
        "# Pembuatan Model (Menambah Model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AU7VY6zc9BRK",
        "outputId": "dd2d3a15-5ea2-4ade-c2c4-29b1179470a1"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "                             base_model,\n",
        "                             tf.keras.layers.Flatten(),\n",
        "                             tf.keras.layers.Dense(512, activation='relu'),\n",
        "                             tf.keras.layers.Dropout(rate=0.2),\n",
        "                             tf.keras.layers.Dense(3, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 227 ms (started: 2021-01-24 16:57:39 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2V83N5i4Pn_q",
        "outputId": "cdcd6c84-8a59-43cd-a60b-230b2b824854"
      },
      "source": [
        "model.compile(\"adam\",loss=\"categorical_crossentropy\",metrics=[\"acc\"])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "mobilenet_1.00_224 (Function (None, 7, 7, 1024)        3228864   \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 50176)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               25690624  \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 1539      \n",
            "=================================================================\n",
            "Total params: 28,921,027\n",
            "Trainable params: 25,692,163\n",
            "Non-trainable params: 3,228,864\n",
            "_________________________________________________________________\n",
            "time: 24.4 ms (started: 2021-01-24 16:57:40 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUPeyHkJlb4_"
      },
      "source": [
        "# Menambah Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECjFOcQ5C6h_",
        "outputId": "5ffddae6-7837-4e53-d361-6cd5eb907889"
      },
      "source": [
        "#es = EarlyStopping(monitor=\"val_loss\", patience=7, verbose=1, min_delta=0.09, mode=\"auto\")\n",
        "history = model.fit(train_generator,\n",
        "                    epochs=50,\n",
        "                    validation_data=val_generator)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "6/6 [==============================] - 16s 2s/step - loss: 34.4197 - acc: 0.3219 - val_loss: 18.3245 - val_acc: 0.5432\n",
            "Epoch 2/50\n",
            "6/6 [==============================] - 9s 2s/step - loss: 12.3412 - acc: 0.4628 - val_loss: 4.4285 - val_acc: 0.4259\n",
            "Epoch 3/50\n",
            "6/6 [==============================] - 9s 2s/step - loss: 3.1221 - acc: 0.5211 - val_loss: 1.7958 - val_acc: 0.5556\n",
            "Epoch 4/50\n",
            "6/6 [==============================] - 9s 2s/step - loss: 1.5782 - acc: 0.5858 - val_loss: 0.9819 - val_acc: 0.6543\n",
            "Epoch 5/50\n",
            "6/6 [==============================] - 9s 2s/step - loss: 0.7373 - acc: 0.6506 - val_loss: 0.8027 - val_acc: 0.6173\n",
            "Epoch 6/50\n",
            "6/6 [==============================] - 9s 1s/step - loss: 0.7827 - acc: 0.6295 - val_loss: 0.6919 - val_acc: 0.6543\n",
            "Epoch 7/50\n",
            "6/6 [==============================] - 9s 2s/step - loss: 0.6767 - acc: 0.6429 - val_loss: 0.6890 - val_acc: 0.6605\n",
            "Epoch 8/50\n",
            "6/6 [==============================] - 9s 2s/step - loss: 0.6413 - acc: 0.6895 - val_loss: 0.6719 - val_acc: 0.7160\n",
            "Epoch 9/50\n",
            "6/6 [==============================] - 9s 2s/step - loss: 0.5447 - acc: 0.7723 - val_loss: 0.5768 - val_acc: 0.7716\n",
            "Epoch 10/50\n",
            "6/6 [==============================] - 9s 2s/step - loss: 0.5387 - acc: 0.7710 - val_loss: 0.5988 - val_acc: 0.7407\n",
            "Epoch 11/50\n",
            "6/6 [==============================] - 9s 2s/step - loss: 0.5337 - acc: 0.7448 - val_loss: 0.6376 - val_acc: 0.7222\n",
            "Epoch 12/50\n",
            "6/6 [==============================] - 9s 2s/step - loss: 0.4978 - acc: 0.7932 - val_loss: 0.5419 - val_acc: 0.7531\n",
            "Epoch 13/50\n",
            "6/6 [==============================] - 9s 2s/step - loss: 0.4212 - acc: 0.8075 - val_loss: 0.5448 - val_acc: 0.7778\n",
            "Epoch 14/50\n",
            "6/6 [==============================] - 9s 1s/step - loss: 0.3959 - acc: 0.8468 - val_loss: 0.6444 - val_acc: 0.7284\n",
            "Epoch 15/50\n",
            "6/6 [==============================] - 9s 1s/step - loss: 0.3767 - acc: 0.8555 - val_loss: 0.4959 - val_acc: 0.7778\n",
            "Epoch 16/50\n",
            "6/6 [==============================] - 9s 2s/step - loss: 0.3887 - acc: 0.8324 - val_loss: 0.6093 - val_acc: 0.7654\n",
            "Epoch 17/50\n",
            "6/6 [==============================] - 9s 2s/step - loss: 0.3647 - acc: 0.8564 - val_loss: 0.4907 - val_acc: 0.7840\n",
            "Epoch 18/50\n",
            "6/6 [==============================] - 9s 2s/step - loss: 0.3088 - acc: 0.8760 - val_loss: 0.5188 - val_acc: 0.7840\n",
            "Epoch 19/50\n",
            "6/6 [==============================] - 9s 2s/step - loss: 0.2841 - acc: 0.8818 - val_loss: 0.4834 - val_acc: 0.7901\n",
            "Epoch 20/50\n",
            "6/6 [==============================] - 9s 1s/step - loss: 0.2872 - acc: 0.8937 - val_loss: 0.5304 - val_acc: 0.7407\n",
            "Epoch 21/50\n",
            "6/6 [==============================] - 9s 1s/step - loss: 0.2799 - acc: 0.8810 - val_loss: 0.4773 - val_acc: 0.8148\n",
            "Epoch 22/50\n",
            "6/6 [==============================] - 9s 1s/step - loss: 0.2988 - acc: 0.9008 - val_loss: 0.6038 - val_acc: 0.7778\n",
            "Epoch 23/50\n",
            "6/6 [==============================] - 9s 1s/step - loss: 0.2932 - acc: 0.8824 - val_loss: 0.4461 - val_acc: 0.8148\n",
            "Epoch 24/50\n",
            "6/6 [==============================] - 9s 1s/step - loss: 0.3036 - acc: 0.8775 - val_loss: 0.5682 - val_acc: 0.7778\n",
            "Epoch 25/50\n",
            "6/6 [==============================] - 9s 2s/step - loss: 0.2678 - acc: 0.9033 - val_loss: 0.5499 - val_acc: 0.7654\n",
            "Epoch 26/50\n",
            "6/6 [==============================] - 9s 2s/step - loss: 0.3071 - acc: 0.8674 - val_loss: 0.5291 - val_acc: 0.7593\n",
            "Epoch 27/50\n",
            "6/6 [==============================] - 9s 1s/step - loss: 0.2377 - acc: 0.9106 - val_loss: 0.5832 - val_acc: 0.8025\n",
            "Epoch 28/50\n",
            "6/6 [==============================] - 9s 2s/step - loss: 0.3250 - acc: 0.8753 - val_loss: 0.5748 - val_acc: 0.7469\n",
            "Epoch 29/50\n",
            "6/6 [==============================] - 9s 1s/step - loss: 0.2212 - acc: 0.9189 - val_loss: 0.4785 - val_acc: 0.7901\n",
            "Epoch 30/50\n",
            "6/6 [==============================] - 9s 1s/step - loss: 0.2408 - acc: 0.8915 - val_loss: 0.5562 - val_acc: 0.8025\n",
            "Epoch 31/50\n",
            "6/6 [==============================] - 9s 2s/step - loss: 0.2272 - acc: 0.9128 - val_loss: 0.4612 - val_acc: 0.7963\n",
            "Epoch 32/50\n",
            "6/6 [==============================] - 9s 2s/step - loss: 0.3160 - acc: 0.8638 - val_loss: 0.6043 - val_acc: 0.7840\n",
            "Epoch 33/50\n",
            "6/6 [==============================] - 9s 2s/step - loss: 0.2034 - acc: 0.9024 - val_loss: 0.5475 - val_acc: 0.7716\n",
            "Epoch 34/50\n",
            "6/6 [==============================] - 9s 1s/step - loss: 0.2260 - acc: 0.9040 - val_loss: 0.5190 - val_acc: 0.7901\n",
            "Epoch 35/50\n",
            "6/6 [==============================] - 9s 2s/step - loss: 0.2066 - acc: 0.8999 - val_loss: 0.4727 - val_acc: 0.7963\n",
            "Epoch 36/50\n",
            "6/6 [==============================] - 9s 2s/step - loss: 0.2071 - acc: 0.9182 - val_loss: 0.5396 - val_acc: 0.7840\n",
            "Epoch 37/50\n",
            "6/6 [==============================] - 9s 1s/step - loss: 0.2240 - acc: 0.9116 - val_loss: 0.5567 - val_acc: 0.7840\n",
            "Epoch 38/50\n",
            "6/6 [==============================] - 9s 1s/step - loss: 0.1778 - acc: 0.9279 - val_loss: 0.5306 - val_acc: 0.8025\n",
            "Epoch 39/50\n",
            "6/6 [==============================] - 9s 1s/step - loss: 0.1983 - acc: 0.9207 - val_loss: 0.6666 - val_acc: 0.7469\n",
            "Epoch 40/50\n",
            "6/6 [==============================] - 9s 1s/step - loss: 0.1720 - acc: 0.9433 - val_loss: 0.6056 - val_acc: 0.7963\n",
            "Epoch 41/50\n",
            "6/6 [==============================] - 9s 2s/step - loss: 0.1987 - acc: 0.9347 - val_loss: 0.6980 - val_acc: 0.7716\n",
            "Epoch 42/50\n",
            "6/6 [==============================] - 9s 1s/step - loss: 0.2004 - acc: 0.9279 - val_loss: 0.5437 - val_acc: 0.7778\n",
            "Epoch 43/50\n",
            "6/6 [==============================] - 9s 2s/step - loss: 0.1548 - acc: 0.9491 - val_loss: 0.4618 - val_acc: 0.8642\n",
            "Epoch 44/50\n",
            "6/6 [==============================] - 9s 1s/step - loss: 0.1367 - acc: 0.9521 - val_loss: 0.5755 - val_acc: 0.7346\n",
            "Epoch 45/50\n",
            "6/6 [==============================] - 9s 1s/step - loss: 0.1619 - acc: 0.9365 - val_loss: 0.5093 - val_acc: 0.8086\n",
            "Epoch 46/50\n",
            "6/6 [==============================] - 9s 1s/step - loss: 0.1906 - acc: 0.9223 - val_loss: 0.6207 - val_acc: 0.7901\n",
            "Epoch 47/50\n",
            "6/6 [==============================] - 9s 2s/step - loss: 0.1755 - acc: 0.9210 - val_loss: 0.5865 - val_acc: 0.8148\n",
            "Epoch 48/50\n",
            "6/6 [==============================] - 9s 1s/step - loss: 0.1627 - acc: 0.9460 - val_loss: 0.6215 - val_acc: 0.7716\n",
            "Epoch 49/50\n",
            "3/6 [==============>...............] - ETA: 4s - loss: 0.1713 - acc: 0.9149"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZS0Fl9MwlgeP"
      },
      "source": [
        "# Menampilkan Grafik Model Hasil Pelatihan"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6-X4DuVDe0c"
      },
      "source": [
        "fig = plt.figure(figsize=(7, 4))\n",
        "fig.set_figheight(10)\n",
        "fig.set_figwidth(15)\n",
        " \n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(history.history[\"acc\"], label = \"Training Accuracy\")\n",
        "plt.plot(history.history[\"val_acc\"], label=\"Validation Accuracy\")\n",
        "plt.legend()\n",
        "plt.title(\"Kurva Tingkat Akurasi\", size=15)\n",
        "plt.grid(zorder=0)\n",
        " \n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n",
        "plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
        "plt.legend()\n",
        "plt.title(\"Kurva Tingkat Error\", size=15)\n",
        "plt.grid(zorder=0)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqEvNlQ3lo8_"
      },
      "source": [
        "# Menggunakan Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVcJp59RRuZb"
      },
      "source": [
        "print(train_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNLVBnrKIR2b"
      },
      "source": [
        "y_test2 = to_categorical(y_test)\n",
        "X_test3, y_test3 = (X_test, y_test2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBTwhYAZl1Tp"
      },
      "source": [
        "# Evaluasi Jaringan"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9QKNCOtZLBX"
      },
      "source": [
        "#Menampilkan matriks yang benar dan matriks hasil prediksi\n",
        "\n",
        "#Label yang benar\n",
        "y_true = np.argmax(y_test2,axis=1)\n",
        "\n",
        "#Label prediksi\n",
        "Y_pred = model.predict(X_test)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "\n",
        "print(y_true)\n",
        "print(y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8Md77cRlxg-"
      },
      "source": [
        "# Membuat Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7htaR09EFZKG"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, classes,\n",
        "                          normalize=False,\n",
        "                          title=None,\n",
        "                          cmap=plt.cm.Blues):\n",
        "  \"\"\"\n",
        "  This function prints and plots the confusion matrix.\n",
        "  Normalization can be applied by setting `normalize=True`.\n",
        "  \"\"\"\n",
        "  if not title:\n",
        "    if normalize:\n",
        "      title = 'Normalized confusion matrix'\n",
        "    else:\n",
        "      title = 'Confusion matrix, without normalization'\n",
        "\n",
        "  #compute confusion matrix\n",
        "  cm = confusion_matrix(y_true, y_pred)\n",
        "  #Only use the labels that appear in the data\n",
        "  #classes = classes[unique_labels(y_true, y_pred)]\n",
        "  if normalize:\n",
        "    cm = cm.astype('float') / cm.sum(axis=1)[:, np. newaxis]\n",
        "    print(\"Normalized confusion matrix\")\n",
        "  else:\n",
        "    print('Confusion matrix, without normalization')\n",
        "\n",
        "  print(cm)\n",
        "\n",
        "  fig, ax = plt.subplots(figsize=(5,5))\n",
        "  im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "  #ax.figure.colorbar(im, ax=ax)\n",
        "  #we want to show all ticks...\n",
        "  ax.set(xticks=np.arange(cm.shape[1]),\n",
        "         yticks=np.arange(cm.shape[0]),\n",
        "         #...and label them with the respective list entries\n",
        "         xticklabels=classes, yticklabels=classes,\n",
        "         title=title,\n",
        "         ylabel='Label Benar',\n",
        "         xlabel='Label Prediksi')\n",
        "  \n",
        "  #Rotate the tick labels and set their alignment.\n",
        "  plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "           rotation_mode=\"anchor\")\n",
        "  #Loop over data dimensions and create text annotations.\n",
        "  fmt = '.2f' if normalize else 'd'\n",
        "  thresh = cm.max() / 2.\n",
        "  for i in range(cm.shape[0]):\n",
        "    for j in range(cm.shape[1]):\n",
        "      ax.text(j, i, format(cm[i, j], fmt),\n",
        "              ha=\"center\", va=\"center\",\n",
        "              color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "      fig.tight_layout()\n",
        "      return ax\n",
        "\n",
        "np.set_printoptions(precision=2)\n",
        "\n",
        "plot_confusion_matrix(y_true, y_pred, classes=labels, normalize=True,\n",
        "                      title='Normalized confusion matrix')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWW4IeH0mBep"
      },
      "source": [
        "# Menyimpan dan Mengkonversi Model ke \".tflite\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xe5Ty0t7kF7U"
      },
      "source": [
        "saved_model_dir = 'save/model'\n",
        "tf.saved_model.save(model, saved_model_dir)\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "with open('Emotion_Detection_MobileNet.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NavALtxUmKOJ"
      },
      "source": [
        "# Menyimpan model tflite versi kompatibel quantized"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LPqyOXrkTqF"
      },
      "source": [
        "saved_model_dir = 'save/model'\n",
        "tf.saved_model.save(model, saved_model_dir)\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_quant_model = converter.convert()\n",
        "\n",
        "with open('Emotion_Detection_MobileNet_Quantized', 'wb') as f:\n",
        "  f.write(tflite_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvxCKXSHy8kT"
      },
      "source": [
        "n = 1\n",
        "\n",
        "plt.imshow(X_test[n])\n",
        "plt.show()\n",
        "\n",
        "true_label = np.argmax(y_test2,axis=1) [n]\n",
        "print(\"Label yang benar adalah:\", true_label,\":\", labels[true_label])\n",
        "prediction = model.predict(X_test[n][np.newaxis,...])[0]\n",
        "print(\"Nilai yang diprediksi adalah:\",prediction)\n",
        "predicted_label = np.argmax(prediction)\n",
        "print(\"Label yang diprediksi adalah:\",predicted_label,\":\",labels[predicted_label])\n",
        "\n",
        "if true_label == predicted_label:\n",
        "  print(\"Prediksi benar\")\n",
        "else:\n",
        "  print(\"Prediksi salah\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4pihwTrmO1U"
      },
      "source": [
        "# Penggunaan Model Pada Gambar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shJLfY8dWV5k"
      },
      "source": [
        "import cv2\r\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOgvevTla_vV"
      },
      "source": [
        "image = cv2.imread('/content/drive/MyDrive/Colab Notebooks/PENGUJIAN/marah.jpeg')\r\n",
        "orig = image.copy()\r\n",
        "(h,w) = image.shape[:2]\r\n",
        "\r\n",
        "blob = cv2.dnn.blobFromImage(image, 1.0, (300,300),\r\n",
        "                             (104.0, 177.0, 123.0))\r\n",
        "\r\n",
        "net = cv2.dnn.readNet('/content/drive/MyDrive/Colab Notebooks/Face_detector/deploy.prototxt', '/content/drive/MyDrive/Colab Notebooks/Face_detector/res10_300x300_ssd_iter_140000.caffemodel')\r\n",
        "\r\n",
        "#melewatkan blob melalui jaringan dan mendapatkan deteksi wajah\r\n",
        "print(\"Mendeteksi Wajah...\")\r\n",
        "net.setInput(blob)\r\n",
        "detections = net.forward()\r\n",
        "\r\n",
        "for i in range(0, detections.shape[0]):\r\n",
        "  #ekstrak keyakinan (probabilitas) yang terkait dengan deteksi\r\n",
        "  confidence = detections[0, 0, i, 2]\r\n",
        "  \r\n",
        "  if confidence > 0.5:\r\n",
        "    box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\r\n",
        "    (startX, startY, endX, endY) = box.astype(\"int\")\r\n",
        "\r\n",
        "    (startX, startY) = (max(0, startX), max(0, startY))\r\n",
        "    (endX, endY) = (min(w-1, endX), min(h-1, endY))\r\n",
        "  \r\n",
        "  # Ekstrak ROI wajah, konversikan dari BGR ke pemesanan saluran RGB,\r\n",
        "  # dan mengubah ukurannya menjadi 224x224, dan lalu pre-proses\r\n",
        "  face = image [startY:endY, startX:endX]\r\n",
        "  face = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\r\n",
        "  face = cv2.resize(face, (224, 224))\r\n",
        "  face = img_to_array(face)\r\n",
        "  face = preprocess_input(face)\r\n",
        "  face = np.expand_dims(face, axis=0)\r\n",
        "  \r\n",
        "  # Membaca wajah dengan model\r\n",
        "  (Marah, Sedih, Senang) = model.predict(face)[0]\r\n",
        "  \r\n",
        "  # Marah warna merah, sedih warna hijau dan senang warna biru\r\n",
        "  if (Marah>Sedih and Marah>Senang):\r\n",
        "    label = \"marah\"\r\n",
        "  elif (Sedih>Senang and Sedih>Marah):\r\n",
        "    label = \"sedih\"\r\n",
        "  elif (Senang>Sedih and Senang>Marah):\r\n",
        "    label = \"senang\"\r\n",
        "\r\n",
        "  if label == \"sedih\":\r\n",
        "    color = (0, 255, 0)\r\n",
        "  elif label == \"marah\":\r\n",
        "    color = (0, 0, 255)\r\n",
        "  elif label == \"senang\":\r\n",
        "    color = (255, 0, 0)\r\n",
        "  \r\n",
        "  # Probabilitas hasil deteksi\r\n",
        "  label = \"{}: {:.2f}%\".format(label, max(Marah, Sedih, Senang) * 100)\r\n",
        "  \r\n",
        "  # Menampilkan hasil dengan label dan kotak\r\n",
        "  cv2.putText(image, label, (startX, startY - 10),\r\n",
        "              cv2.FONT_HERSHEY_TRIPLEX, 1, color, 2)\r\n",
        "  cv2.rectangle(image, (startX, startY), (endX, endY), color, 2)\r\n",
        "  \r\n",
        "# Menampilkan output\r\n",
        "cv2_imshow(image)\r\n",
        "cv2.waitKey(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNxDKWNHv58q"
      },
      "source": [
        "Menguji Model Secara Realtime"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CDZjXjlwNpC"
      },
      "source": [
        "# Mengimport lib\r\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\r\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\r\n",
        "from tensorflow.keras.models import load_model\r\n",
        "from imutils.video import VideoStream\r\n",
        "import numpy as np\r\n",
        "import argparse\r\n",
        "import imutils\r\n",
        "import time\r\n",
        "import cv2\r\n",
        "import os\r\n",
        "\r\n",
        "\r\n",
        "def detect_and_predict_emotion(frame, faceNet, emotionNet):\r\n",
        "  #membuat dimensi kotak deteksi\r\n",
        "  (h, w) = frame.shape[:2]\r\n",
        "  blob = cv2.dnn.blobFromImage(frame, 1.0, (300, 300),\r\n",
        "                               (104.0, 177.0, 123.0))\r\n",
        " \r\n",
        "  # Melewatkan blob dan mendeteksi wajah\r\n",
        "  faceNet.setInput(blob)\r\n",
        "  detections = faceNet.forward()\r\n",
        " \r\n",
        "  # Inisialisasi\r\n",
        "  faces = []\r\n",
        "  locs = []\r\n",
        "  preds = []\r\n",
        " \r\n",
        "  for i in range(0, detections.shape[2]):\r\n",
        "    # ekstrak keyakinan (yaitu, probabilitas) yang terkait dengan deteksi\r\n",
        "    confidence = detections[0, 0, i, 2]\r\n",
        "    \r\n",
        "    if confidence > 0.5:\r\n",
        "      # Menghitung koordinat (x, y) dari kotak pembatas untuk objek\r\n",
        "      box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\r\n",
        "      (startX, startY, endX, endY) = box.astype(\"int\")\r\n",
        " \r\n",
        "      # Memastikan kotak pembatas berada dalam dimensi bingkai\r\n",
        "      (startX, startY) = (max(0, startX), max(0, startY))\r\n",
        "      (endX, endY) = (min(w - 1, endX), min(h - 1, endY))\r\n",
        " \r\n",
        "      # Ekstrak ROI wajah, konversikan dari BGR ke pemesanan saluran RGB,\r\n",
        "      # dan mengubah ukurannya menjadi 224x224, dan lalu pre-proses\r\n",
        "      face = frame[startY:endY, startX:endX]\r\n",
        "      face = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\r\n",
        "      face = cv2.resize(face, (224, 224))\r\n",
        "      face = img_to_array(face)\r\n",
        "      face = preprocess_input(face)\r\n",
        " \r\n",
        "      # Menambahkan kotak deteksi\r\n",
        "      faces.append(face)\r\n",
        "      locs.append((startX, startY, endX, endY))\r\n",
        "      \r\n",
        "    if len(faces) > 0:\r\n",
        "      faces = np.array(faces, dtype=\"float32\")\r\n",
        "      preds = emotionNet.predict(faces, batch_size=128)\r\n",
        "    return (locs, preds)\r\n",
        " \r\n",
        "faceNet=cv2.dnn.readNet('/content/drive/MyDrive/Colab Notebooks/Face_detector/deploy.prototxt','/content/drive/MyDrive/Colab Notebooks/Face_detector/res10_300x300_ssd_iter_140000.caffemodel')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evH18lrExJss"
      },
      "source": [
        "import base64\r\n",
        "import html\r\n",
        "import io\r\n",
        "import time\r\n",
        " \r\n",
        "from IPython.display import display, Javascript\r\n",
        "from google.colab.output import eval_js\r\n",
        "import numpy as np\r\n",
        "from PIL import Image\r\n",
        "import cv2\r\n",
        " \r\n",
        "def start_input():\r\n",
        "  js = Javascript('''\r\n",
        "    var video;\r\n",
        "    var div = null;\r\n",
        "    var stream;\r\n",
        "    var captureCanvas;\r\n",
        "    var imgElement;\r\n",
        "    var labelElement;\r\n",
        "    \r\n",
        "    var pendingResolve = null;\r\n",
        "    var shutdown = false;\r\n",
        "    \r\n",
        "    function removeDom() {\r\n",
        "       stream.getVideoTracks()[0].stop();\r\n",
        "       video.remove();\r\n",
        "       div.remove();\r\n",
        "       video = null;\r\n",
        "       div = null;\r\n",
        "       stream = null;\r\n",
        "       imgElement = null;\r\n",
        "       captureCanvas = null;\r\n",
        "       labelElement = null;\r\n",
        "    }\r\n",
        "    \r\n",
        "    function onAnimationFrame() {\r\n",
        "      if (!shutdown) {\r\n",
        "        window.requestAnimationFrame(onAnimationFrame);\r\n",
        "      }\r\n",
        "      if (pendingResolve) {\r\n",
        "        var result = \"\";\r\n",
        "        if (!shutdown) {\r\n",
        "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 512, 512);\r\n",
        "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\r\n",
        "        }\r\n",
        "        var lp = pendingResolve;\r\n",
        "        pendingResolve = null;\r\n",
        "        lp(result);\r\n",
        "      }\r\n",
        "    }\r\n",
        "    \r\n",
        "    async function createDom() {\r\n",
        "      if (div !== null) {\r\n",
        "        return stream;\r\n",
        "      }\r\n",
        "      div = document.createElement('div');\r\n",
        "      div.style.border = '2px solid black';\r\n",
        "      div.style.padding = '3px';\r\n",
        "      div.style.width = '100%';\r\n",
        "      div.style.maxWidth = '600px';\r\n",
        "      document.body.appendChild(div);\r\n",
        "      \r\n",
        "      const modelOut = document.createElement('div');\r\n",
        "      modelOut.innerHTML = \"<span>Status:</span>\";\r\n",
        "      labelElement = document.createElement('span');\r\n",
        "      labelElement.innerText = 'No data';\r\n",
        "      labelElement.style.fontWeight = 'bold';\r\n",
        "      modelOut.appendChild(labelElement);\r\n",
        "      div.appendChild(modelOut);\r\n",
        "           \r\n",
        "      video = document.createElement('video');\r\n",
        "      video.style.display = 'block';\r\n",
        "      video.width = div.clientWidth - 6;\r\n",
        "      video.setAttribute('playsinline', '');\r\n",
        "      video.onclick = () => { shutdown = true; };\r\n",
        "      stream = await navigator.mediaDevices.getUserMedia(\r\n",
        "          {video: { facingMode: \"environment\"}});\r\n",
        "      div.appendChild(video);\r\n",
        "      imgElement = document.createElement('img');\r\n",
        "      imgElement.style.position = 'absolute';\r\n",
        "      imgElement.style.zIndex = 1;\r\n",
        "      imgElement.onclick = () => { shutdown = true; };\r\n",
        "      div.appendChild(imgElement);\r\n",
        "      \r\n",
        "      const instruction = document.createElement('div');\r\n",
        "      instruction.innerHTML = \r\n",
        "          '<span style=\"color: red; font-weight: bold;\">' +\r\n",
        "          'Ketika selesai, klik disini atau pada video untuk berhenti dari demo</span>';\r\n",
        "      div.appendChild(instruction);\r\n",
        "      instruction.onclick = () => { shutdown = true; };\r\n",
        "      \r\n",
        "      video.srcObject = stream;\r\n",
        "      await video.play();\r\n",
        "      captureCanvas = document.createElement('canvas');\r\n",
        "      captureCanvas.width = 512; //video.videoWidth;\r\n",
        "      captureCanvas.height = 512; //video.videoHeight;\r\n",
        "      window.requestAnimationFrame(onAnimationFrame);\r\n",
        "      \r\n",
        "      return stream;\r\n",
        "    }\r\n",
        "    async function takePhoto(label, imgData) {\r\n",
        "      if (shutdown) {\r\n",
        "        removeDom();\r\n",
        "        shutdown = false;\r\n",
        "        return '';\r\n",
        "      }\r\n",
        "      var preCreate = Date.now();\r\n",
        "      stream = await createDom();\r\n",
        "      \r\n",
        "      var preShow = Date.now();\r\n",
        "      if (label != \"\") {\r\n",
        "        labelElement.innerHTML = label;\r\n",
        "      }\r\n",
        "            \r\n",
        "      if (imgData != \"\") {\r\n",
        "        var videoRect = video.getClientRects()[0];\r\n",
        "        imgElement.style.top = videoRect.top + \"px\";\r\n",
        "        imgElement.style.left = videoRect.left + \"px\";\r\n",
        "        imgElement.style.width = videoRect.width + \"px\";\r\n",
        "        imgElement.style.height = videoRect.height + \"px\";\r\n",
        "        imgElement.src = imgData;\r\n",
        "      }\r\n",
        "      \r\n",
        "      var preCapture = Date.now();\r\n",
        "      var result = await new Promise(function(resolve, reject) {\r\n",
        "        pendingResolve = resolve;\r\n",
        "      });\r\n",
        "      shutdown = false;\r\n",
        "      \r\n",
        "      return {'create': preShow - preCreate, \r\n",
        "              'show': preCapture - preShow, \r\n",
        "              'capture': Date.now() - preCapture,\r\n",
        "              'img': result};\r\n",
        "    }\r\n",
        "    ''')\r\n",
        " \r\n",
        "  display(js)\r\n",
        "  \r\n",
        "def take_photo(label, img_data):\r\n",
        "  data = eval_js('takePhoto(\"{}\", \"{}\")'.format(label, img_data))\r\n",
        "  return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3J9nONYXxaha"
      },
      "source": [
        "def js_reply_to_image(js_reply):\r\n",
        "    \"\"\"\r\n",
        "    input: \r\n",
        "          js_reply: JavaScript object, contain image from webcam\r\n",
        "    output: \r\n",
        "          image_array: image array RGB size 512 x 512 from webcam\r\n",
        "    \"\"\"\r\n",
        "    jpeg_bytes = base64.b64decode(js_reply['img'].split(',')[1])\r\n",
        "    image_PIL = Image.open(io.BytesIO(jpeg_bytes))\r\n",
        "    image_array = np.array(image_PIL)\r\n",
        " \r\n",
        "    return image_array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmJyPNH2xebJ"
      },
      "source": [
        "start_input()\r\n",
        "label_html = 'Capturing...'\r\n",
        "img_data = ''\r\n",
        "count = 0 \r\n",
        "from google.colab.patches import cv2_imshow\r\n",
        "while True:\r\n",
        "  js_reply = take_photo(label_html, img_data)\r\n",
        "  if not js_reply:\r\n",
        "    break\r\n",
        "  \r\n",
        "  image = js_reply_to_image(js_reply)\r\n",
        "  \r\n",
        "  # Mengambil frame dari aliran video berulir dan \r\n",
        "  # ukurannya maksimum lebar 400 pixel\r\n",
        "  frame = image\r\n",
        "  v=True\r\n",
        "  if v == True:\r\n",
        "    \r\n",
        "    frame = imutils.resize(frame, width=400)\r\n",
        "    \r\n",
        "    # Mendeteksi emosi\r\n",
        "    (locs, preds) = detect_and_predict_emotion(frame, faceNet, model)\r\n",
        "    for (box, pred) in zip(locs, preds):\r\n",
        "      \r\n",
        "      # Membuka kotak dan prediksi\r\n",
        "      (startX, startY, endX, endY) = box\r\n",
        "      (Marah, Sedih, Senang) = pred\r\n",
        "\r\n",
        "      # Menggunakan masker hijau, tidak bermasker merah\r\n",
        "      if (Marah>Sedih and Marah>Senang):\r\n",
        "        label = \"sedih\"\r\n",
        "      elif (Sedih>Senang and Sedih>Marah):\r\n",
        "        label = \"marah\"\r\n",
        "      elif (Senang>Marah and Senang>Sedih):\r\n",
        "        label = \"senang\"\r\n",
        "        \r\n",
        "      if label == \"marah\":\r\n",
        "        color = (0, 255, 0)\r\n",
        "      elif label == \"sedih\":\r\n",
        "        color = (0, 0, 255)\r\n",
        "      elif label == \"senang\" :\r\n",
        "        color = (255, 0, 0)\r\n",
        "        \r\n",
        "      # Probabilitas pada label\r\n",
        "      label = \"{}: {:.2f}%\".format(label, max(Marah, Sedih, Senang) * 100)\r\n",
        "      \r\n",
        "      # Menampilkan hasil dengan label dan kotak dari frame\r\n",
        "      frame=cv2.putText(frame, label, (startX, startY - 10),cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\r\n",
        "      frame=cv2.rectangle(frame, (startX, startY), (endX, endY), color, 2)\r\n",
        "      # Menampilkan ouput\r\n",
        "      cv2_imshow(frame)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}